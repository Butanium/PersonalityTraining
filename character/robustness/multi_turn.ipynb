{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98c7c5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, evaluate, shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as t\n",
    "from random import shuffle\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "from datasets import Dataset\n",
    "from character.utils import constitutions\n",
    "from character.constants import DATA_PATH, MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17891d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL2ID = {cons: i for i, cons in enumerate(constitutions)}\n",
    "ID2LABEL = {v: k for k, v in LABEL2ID.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4787b265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model_name: str, variant: str) -> tuple[float, float]:\n",
    "    model_name_stem = model_name.split(\"-\")[0]\n",
    "    tokenizer = AutoTokenizer.from_pretrained(f\"{MODEL_PATH}/classifier-{model_name_stem}\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        f\"{MODEL_PATH}/classifier-{model_name_stem}\",\n",
    "        torch_dtype=t.bfloat16,\n",
    "        device_map=\"cuda\",\n",
    "        trust_remote_code=True,\n",
    "        num_labels=len(LABEL2ID),\n",
    "        id2label=ID2LABEL,\n",
    "        label2id=LABEL2ID,\n",
    "        problem_type=\"single_label_classification\"\n",
    "    )\n",
    "\n",
    "    PATH = f\"{DATA_PATH}/robustness/{model_name}/multi_turn\"\n",
    "\n",
    "    dataset = []\n",
    "    for constitution in constitutions:\n",
    "        path = f\"{PATH}/{variant}/{constitution}.jsonl\"\n",
    "        if not os.path.exists(path): continue\n",
    "        data = pd.read_json(path, lines=True, orient=\"records\")\n",
    "        elements = []\n",
    "        for text in data[\"response\"]:\n",
    "            out = tokenizer(text, truncation=True, max_length=8192).to(model.device)\n",
    "            out[\"label\"] = LABEL2ID[constitution]\n",
    "            elements.append(out)\n",
    "        dataset.extend(elements)\n",
    "    shuffle(dataset)\n",
    "    dataset = Dataset.from_list(dataset)\n",
    "\n",
    "    metric_f1 = evaluate.load(\"f1\")\n",
    "    metric_accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "    def compute_metrics(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        preds = np.argmax(logits, axis=-1)\n",
    "        f1_score = metric_f1.compute(predictions=preds, references=labels, average=\"macro\")\n",
    "        accuracy_score = metric_accuracy.compute(predictions=preds, references=labels)  \n",
    "        return {**f1_score, **accuracy_score}\n",
    "\n",
    "    # calculate F1 score and accuracy on the dataset\n",
    "    collator = DataCollatorWithPadding(tokenizer)\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=TrainingArguments(\n",
    "            output_dir=\"temp\",\n",
    "            per_device_eval_batch_size=8,\n",
    "            dataloader_num_workers=4,\n",
    "            report_to=\"none\",\n",
    "        ),\n",
    "        eval_dataset=dataset,\n",
    "        processing_class=tokenizer,\n",
    "        data_collator=collator,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        results = trainer.evaluate()\n",
    "    finally:\n",
    "        if os.path.exists(\"temp\"):\n",
    "            shutil.rmtree(\"temp\")\n",
    "\n",
    "    return results[\"eval_f1\"], results[\"eval_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73fd335a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='688' max='688' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [688/688 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variant: distillation\n",
      "F1 score: 0.7888\n",
      "Accuracy: 0.7813\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='688' max='688' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [688/688 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variant: personas\n",
      "F1 score: 0.9496\n",
      "Accuracy: 0.9525\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "model_name = \"llama-3.1-8b-it\"\n",
    "for variant in [\"distillation\", \"personas\"]:\n",
    "    f1, acc = eval(model_name, variant)\n",
    "    print(f\"Variant: {variant}\")\n",
    "    print(f\"F1 score: {f1:.4f}\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(\"=\"*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
